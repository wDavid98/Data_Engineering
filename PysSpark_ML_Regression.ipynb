{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PySpark: Machine leargning approach**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library and PySpark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Librer√≠as\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://WDRS98:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ML_intr</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1ab17b17850>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "#start session\n",
    "spark = SparkSession.builder.appName('ML_intr').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+------------------------+---------------------------+---------------+-----------+--------------------+\n",
      "|Avg_Area_Income|Avg_Area_House_Age|Avg_Area_Number_of_Rooms|Avg_Area_Number_of_Bedrooms|Area_Population|      Price|             Address|\n",
      "+---------------+------------------+------------------------+---------------------------+---------------+-----------+--------------------+\n",
      "|    79545.45857|       5.682861322|             7.009188143|                       4.09|     23086.8005|1059033.558|208 Michael Ferry...|\n",
      "|    79248.64245|       6.002899808|             6.730821019|                       3.09|    40173.07217|1505890.915|188 Johnson Views...|\n",
      "|    61287.06718|        5.86588984|              8.51272743|                       5.13|     36882.1594|1058987.988|9127 Elizabeth St...|\n",
      "|    63345.24005|       7.188236095|             5.586728665|                       3.26|    34310.24283|1260616.807|USS Barnett\\nFPO ...|\n",
      "|    59982.19723|       5.040554523|             7.839387785|                       4.23|    26354.10947|630943.4893|USNS Raymond\\nFPO...|\n",
      "+---------------+------------------+------------------------+---------------------------+---------------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## read data\n",
    "df = spark.read.format(\"csv\").load(\"data/housing.csv\", header=True, sep=',',inferSchema=True, multiLine=True)\n",
    "df = df.withColumnRenamed(\"Avg. Area Income\", \"Avg_Area_Income\") \\\n",
    "       .withColumnRenamed(\"Avg. Area House Age\", \"Avg_Area_House_Age\") \\\n",
    "       .withColumnRenamed(\"Avg. Area Number of Rooms\", \"Avg_Area_Number_of_Rooms\") \\\n",
    "       .withColumnRenamed(\"Avg. Area Number of Bedrooms\", \"Avg_Area_Number_of_Bedrooms\") \\\n",
    "       .withColumnRenamed(\"Area Population\", \"Area_Population\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML approach: Vector Assembler and Linear Regression\n",
    "A feature transformer that merges several columns into one vector column.\n",
    "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+------------------------+---------------------------+---------------+-----------+--------------------+--------------------+\n",
      "|Avg_Area_Income|Avg_Area_House_Age|Avg_Area_Number_of_Rooms|Avg_Area_Number_of_Bedrooms|Area_Population|      Price|             Address|            features|\n",
      "+---------------+------------------+------------------------+---------------------------+---------------+-----------+--------------------+--------------------+\n",
      "|    79545.45857|       5.682861322|             7.009188143|                       4.09|     23086.8005|1059033.558|208 Michael Ferry...|[7.009188143,5.68...|\n",
      "|    79248.64245|       6.002899808|             6.730821019|                       3.09|    40173.07217|1505890.915|188 Johnson Views...|[6.730821019,6.00...|\n",
      "|    61287.06718|        5.86588984|              8.51272743|                       5.13|     36882.1594|1058987.988|9127 Elizabeth St...|[8.51272743,5.865...|\n",
      "|    63345.24005|       7.188236095|             5.586728665|                       3.26|    34310.24283|1260616.807|USS Barnett\\nFPO ...|[5.586728665,7.18...|\n",
      "|    59982.19723|       5.040554523|             7.839387785|                       4.23|    26354.10947|630943.4893|USNS Raymond\\nFPO...|[7.839387785,5.04...|\n",
      "+---------------+------------------+------------------------+---------------------------+---------------+-----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-----------+\n",
      "|            features|      Price|\n",
      "+--------------------+-----------+\n",
      "|[7.009188143,5.68...|1059033.558|\n",
      "|[6.730821019,6.00...|1505890.915|\n",
      "|[8.51272743,5.865...|1058987.988|\n",
      "|[5.586728665,7.18...|1260616.807|\n",
      "|[7.839387785,5.04...|630943.4893|\n",
      "+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Import vector assembler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "## let predict price based on the following features: ave number of room and Avg. Area House Age\n",
    "assembler = VectorAssembler(inputCols=['Avg_Area_Number_of_Rooms','Avg_Area_House_Age'], outputCol='features') \n",
    "\n",
    "## train assembler vector\n",
    "output = assembler.transform(df)\n",
    "\n",
    "## This create a columns with the combination of the selected features\n",
    "output.show(5)\n",
    "\n",
    "## select the features that we need\n",
    "final_data = output.select('features','Price')\n",
    "\n",
    "final_data.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [117568.92911530565,159632.21737298174] Intercept: -544509.5799187213\n",
      "+--------------------+-----------+------------------+\n",
      "|            features|      Price|        prediction|\n",
      "+--------------------+-----------+------------------+\n",
      "|[4.290193826,7.23...|934744.0335|1115600.9473878723|\n",
      "|[4.29822055,7.275...|1457230.646| 1122260.008563473|\n",
      "|[4.321938664,7.12...|944491.0396| 1100742.050573925|\n",
      "|[4.347851966,5.70...|957806.0027| 876655.2572450972|\n",
      "|[4.407346082,7.07...|1586889.995|1102405.6910740556|\n",
      "+--------------------+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "RMSE: 290112.72514620423\n",
      "MSE: 84165393291.75703\n",
      "R2: 0.335058472291455\n"
     ]
    }
   ],
   "source": [
    "## Split the data\n",
    "train_data,test_data = final_data.randomSplit([0.7,0.3])\n",
    "\n",
    "## Import Linear Regression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "## Create a Linear Regression Model object\n",
    "lr = LinearRegression(featuresCol='features', labelCol='Price')\n",
    "\n",
    "## Fit the model to the data and call this model lrModel\n",
    "lrModel = lr.fit(train_data)\n",
    "\n",
    "## regressor coefficients\n",
    "print(\"Coefficients: {} Intercept: {}\".format(lrModel.coefficients,lrModel.intercept))\n",
    "\n",
    "## evaluate the model\n",
    "test_results = lrModel.evaluate(test_data)\n",
    "\n",
    "test_results.predictions.show(5)\n",
    "\n",
    "## metrics\n",
    "\n",
    "print(\"RMSE: {}\".format(test_results.rootMeanSquaredError))\n",
    "print(\"MSE: {}\".format(test_results.meanSquaredError))\n",
    "print(\"R2: {}\".format(test_results.r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEng_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
